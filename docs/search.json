[
  {
    "objectID": "posts/palmer-penuins-blog-post/PalmerPenguins.html",
    "href": "posts/palmer-penuins-blog-post/PalmerPenguins.html",
    "title": "Visualizations and Table",
    "section": "",
    "text": "import pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\ntrain.head()\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\n#vectorizing categorical data via hot encoding\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\nX_train.head()\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\nTrue\nFalse\nFalse\nTrue\nFalse\nTrue\nTrue\nFalse\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nX_train_labs = X_train\nX_train_labs['Species'] = train['Species']\ndata_summary = X_train_labs.groupby('Species').aggregate('mean')\ndata_summary.head() #mean of the numeric features\n\n#Lia Notes: \n#1) Body mass of Gentoo very high compared to Adelie and Chinstrap\n\n#2) Culmin length Adelie different than Chinstrap and Gentoo\n\n#3) Chinstrap 100% on Island_Dream as compared to .37 for Adelie and 0 for Gentoo\n\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\nSpecies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdelie Penguin (Pygoscelis adeliae)\n38.961111\n18.380556\n190.527778\n3722.916667\n8.861431\n-25.808814\n0.305556\n0.37963\n0.314815\n1.0\n0.101852\n0.898148\n0.481481\n0.518519\n\n\nChinstrap penguin (Pygoscelis antarctica)\n48.771429\n18.346429\n195.821429\n3739.732143\n9.331004\n-24.567075\n0.000000\n1.00000\n0.000000\n1.0\n0.178571\n0.821429\n0.553571\n0.446429\n\n\nGentoo penguin (Pygoscelis papua)\n47.133696\n14.926087\n216.739130\n5057.336957\n8.252573\n-26.145754\n1.000000\n0.00000\n0.000000\n1.0\n0.076087\n0.923913\n0.532609\n0.467391\nimport plotly.express as plotly\nimport matplotlib.pyplot as plt\nimport numpy as np\n# Plot 3D scatter\nfig = plotly.scatter_3d(\n    X_train,\n    x='Culmen Length (mm)',\n    y='Body Mass (g)',\n    z='Flipper Length (mm)',\n    color='Species',\n    hover_name='Species'\n)\n\n\nfig.show()\n#bar plor of island population ratios\nbar= data_summary[[\"Island_Biscoe\", \"Island_Dream\", \"Island_Torgersen\"]].plot(\n    kind=\"barh\",\n    stacked=True,\n    figsize=(8, 6),\n    colormap=\"viridis\"\n)\n\n#labs :)\nbar.set_title(\"Island Population Ratios by Penguin Species\")\nbar.set_ylabel(\"Population Ratio\")\nbar.set_xlabel(\"Species\")\nbar.legend(title=\"Island\")\nplt.tight_layout()\n\nUnable to display output for mime type(s): application/vnd.plotly.v1+json"
  },
  {
    "objectID": "posts/palmer-penuins-blog-post/PalmerPenguins.html#model-training",
    "href": "posts/palmer-penuins-blog-post/PalmerPenguins.html#model-training",
    "title": "Visualizations and Table",
    "section": "Model Training",
    "text": "Model Training\nfeatures: Dream Island (categorical), Culmin Length (Numeric), and Body Mass (Numeric)\n\n## XGBooste Model\n\n\n\nfrom xgboost import XGBClassifier\n# XGBoost model\n\nxgb_model = XGBClassifier()"
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html",
    "href": "posts/logisticRegression-post/LogisticModel.html",
    "title": "Logistic Regression Blog Post",
    "section": "",
    "text": "https://github.com/Lia-Smith/github.io/blob/main/posts/logisticRegression-post/logistic.py"
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#abstract",
    "href": "posts/logisticRegression-post/LogisticModel.html#abstract",
    "title": "Logistic Regression Blog Post",
    "section": "Abstract",
    "text": "Abstract\nThis blog posts implements logistic regression with momentum gradient descent. I perform experiments comparing the number of steps momentum and vanilla gradient descent take to converge for a randomly generated dataset and a breast cancer classification data set. Additionally, I experiment with overfitting to understand the affects it has on test data outcomes. Finally, I fit the breast cancer test data to see how well the model performs on the dataset.\n\n%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer"
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#gradient-descent-with-momentum",
    "href": "posts/logisticRegression-post/LogisticModel.html#gradient-descent-with-momentum",
    "title": "Logistic Regression Blog Post",
    "section": "Gradient Descent with Momentum",
    "text": "Gradient Descent with Momentum\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\ncross_entropy_loss_b = []\nsteps_b = np.arange(1, 101)\n\nfor i in range(100):\n    opt.step(X, y, alpha=0.1, beta=.9)\n    loss_momentum = LR.loss(X, y)\n    cross_entropy_loss_b.append(loss_momentum);\n\n# Plooooottting Both\n#momentum\nplt.plot(steps_b, cross_entropy_loss_b)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations with Momentum\")\nplt.grid(True)\nplt.show()\n\n# vanilla\nplt.plot(steps, cross_entropy_loss)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations Vanilla\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#comparison-of-vanilla-and-momentum-gradient-descent",
    "href": "posts/logisticRegression-post/LogisticModel.html#comparison-of-vanilla-and-momentum-gradient-descent",
    "title": "Logistic Regression Blog Post",
    "section": "Comparison of Vanilla and Momentum Gradient Descent",
    "text": "Comparison of Vanilla and Momentum Gradient Descent\nThis experiment is designed to illustrate the benefits of a more complex gradient descent algorithm. The above graphs illustrate convergence of the momemtum gradient descent occurs much more rapidly than the vanilla gradient descent. Momentum converges in about a 100 steps while vanilla gradient descent converges in about 2000 steps."
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#overfitting",
    "href": "posts/logisticRegression-post/LogisticModel.html#overfitting",
    "title": "Logistic Regression Blog Post",
    "section": "Overfitting",
    "text": "Overfitting\n\n# two identicle parameter data sets\nLR_overfit = LogisticRegression() \nopt_overfit = GradientDescentOptimizer(LR_overfit)\nX_train, y_train = classification_data(n_points = 50, noise = 0.5, p_dims = 200)\nX_test, y_test = classification_data(n_points = 50, noise = 0.5, p_dims = 200)\n\nadd_bias(X_test) #add ones column for intercept term\nadd_bias(X_train)\n\nfor i in range(1000):\n    opt_overfit.step(X_train, y_train, alpha=0.1, beta=.9)\n    loss = LR_overfit.loss(X_train,y_train);\n    \n    \ny_hat = 1/(1+torch.exp(-LR_overfit.score(X_train)))\nacc_train = torch.abs(y_hat-y_train-1).mean()\nprint(f\"training accuracy: {acc_train}\")\n\ny_hat = 1/(1+torch.exp(-LR_overfit.score(X_test)))\nacc_test = torch.abs(y_hat-y_test-1).mean()\nprint(f\"testing accuracy : {acc_test}\")\n\ntraining accuracy: 0.9998152256011963\ntesting accuracy : 0.8587407469749451"
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#overfitting-experiment",
    "href": "posts/logisticRegression-post/LogisticModel.html#overfitting-experiment",
    "title": "Logistic Regression Blog Post",
    "section": "Overfitting Experiment",
    "text": "Overfitting Experiment\nThis experiment demonstrates the relationship between model complexity and overfitting. As a model becomes more complex, it is likely to capture relationships within the training data that do not generalize to other data. Within this experiment, 150 features yielded 100% accuracy in the training set, but adversely affected the testing data, leading to a lower 83% accuracy."
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#introduction-to-the-data",
    "href": "posts/logisticRegression-post/LogisticModel.html#introduction-to-the-data",
    "title": "Logistic Regression Blog Post",
    "section": "Introduction to the Data",
    "text": "Introduction to the Data\nThe Breast Cancer dataset contains variables derived from digitalized images of a fine needle aspirate (FNA) of a breast mass. The features describe characteristics of the cell nuclie present in the image. This data was compiled from Wisconsin patients. The column diagnosis is a categorical variable with two levels, benign and malignant, which describe whether the mass is benign or malignant. Other variables are continuous variables delineating the various features of the digitized images such as worst_radius of the mass, etc. With this data, I aim to create a model to classify the data using logistic regression with momemtum in gradient descent. Unfortunately I was unable to find the cite the data is originally from.\nWolberg, William, W. Street, and Olvi Mangasarian. “Breast Cancer Wisconsin (Prognostic).” UCI Machine Learning Repository, 1995, https://doi.org/10.24432/C5GK50.\n\nimport pandas as pd\n#reading in the data\nbreast_cancer = pd.read_csv(\"C:/Users/liapu/OneDrive/Desktop/Fall 2024/breast-cancer.csv\")\nbreast_cancer.head()\n\n#turning pd data frames into torch tensors\ntarget = breast_cancer['diagnosis'].map({\"M\": 1, \"B\": 0})\ndata = breast_cancer.drop('diagnosis', axis = 1)\ndata = data.drop('id', axis = 1)\n\nX = torch.tensor(data.values, dtype=torch.float32)\ny = torch.tensor(target.values, dtype = torch.float32)\ndata.head()\n\n\n\n\n\n\n\n\nradius_mean\ntexture_mean\nperimeter_mean\narea_mean\nsmoothness_mean\ncompactness_mean\nconcavity_mean\nconcave points_mean\nsymmetry_mean\nfractal_dimension_mean\n...\nradius_worst\ntexture_worst\nperimeter_worst\narea_worst\nsmoothness_worst\ncompactness_worst\nconcavity_worst\nconcave points_worst\nsymmetry_worst\nfractal_dimension_worst\n\n\n\n\n0\n17.99\n10.38\n122.80\n1001.0\n0.11840\n0.27760\n0.3001\n0.14710\n0.2419\n0.07871\n...\n25.38\n17.33\n184.60\n2019.0\n0.1622\n0.6656\n0.7119\n0.2654\n0.4601\n0.11890\n\n\n1\n20.57\n17.77\n132.90\n1326.0\n0.08474\n0.07864\n0.0869\n0.07017\n0.1812\n0.05667\n...\n24.99\n23.41\n158.80\n1956.0\n0.1238\n0.1866\n0.2416\n0.1860\n0.2750\n0.08902\n\n\n2\n19.69\n21.25\n130.00\n1203.0\n0.10960\n0.15990\n0.1974\n0.12790\n0.2069\n0.05999\n...\n23.57\n25.53\n152.50\n1709.0\n0.1444\n0.4245\n0.4504\n0.2430\n0.3613\n0.08758\n\n\n3\n11.42\n20.38\n77.58\n386.1\n0.14250\n0.28390\n0.2414\n0.10520\n0.2597\n0.09744\n...\n14.91\n26.50\n98.87\n567.7\n0.2098\n0.8663\n0.6869\n0.2575\n0.6638\n0.17300\n\n\n4\n20.29\n14.34\n135.10\n1297.0\n0.10030\n0.13280\n0.1980\n0.10430\n0.1809\n0.05883\n...\n22.54\n16.67\n152.20\n1575.0\n0.1374\n0.2050\n0.4000\n0.1625\n0.2364\n0.07678\n\n\n\n\n5 rows × 30 columns\n\n\n\n\nfrom sklearn.model_selection import train_test_split\n\n# 60% train, 20% val, 20% test (using skit learn :O )\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp)\n\nadd_bias(X_train);\nadd_bias(X_test);\nadd_bias(X_val);\n\n\n#no momentum\ncross_entropy_loss = []\nsteps = np.arange(1, 1001)\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nfor i in range(1000):\n    opt.step(X_train, y_train, alpha=0.1, beta=0)\n    loss = LR.loss(X_train, y_train)\n    cross_entropy_loss.append(loss);\n\n\n #momentum\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\ncross_entropy_loss_b = []\nsteps_b = np.arange(1, 1001)\n\nfor i in range(1000):\n    opt.step(X_train, y_train, alpha=0.01, beta=.9)\n    loss = LR.loss(X_train, y_train)\n    cross_entropy_loss_b.append(loss);\n\n\n# Plooooottting Both\n#momentum\nplt.plot(steps_b, cross_entropy_loss_b)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations with Momentum\")\nplt.grid(True)\nplt.show()\n\n# vanilla\nplt.plot(steps, cross_entropy_loss)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations wthout Momentum\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#validation loss w momentum/ no momentum\n #momentum\nLR_val = LogisticRegression() \nopt_val = GradientDescentOptimizer(LR_val)\n\ncross_entropy_loss_val = []\nsteps_val = np.arange(1, 1001)\n\nfor i in range(1000):\n    opt_val.step(X_val, y_val, alpha=0.01, beta=.9)\n    loss_val = LR_val.loss(X_val, y_val)\n    cross_entropy_loss_val.append(loss_val);\n\n\nLR_val_van = LogisticRegression() \nopt_val_van = GradientDescentOptimizer(LR_val_van)\n\ncross_entropy_loss_val_van = []\nsteps_val_van = np.arange(1, 1001)\n\nfor i in range(1000):\n    opt_val_van.step(X_val, y_val, alpha=0.01, beta=.9)\n    loss_val_van = LR_val_van.loss(X_val, y_val)\n    cross_entropy_loss_val_van.append(loss_val_van);\n\n\n# Plooooottting Both\n#momentum\nplt.plot(steps_val, cross_entropy_loss_val)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations with Momentum\")\nplt.grid(True)\nplt.show()\n\n# vanilla\nplt.plot(steps_val_van, cross_entropy_loss_val_van)\nplt.xlabel(\"Step\")\nplt.ylabel(\"Cross Entropy Loss\")\nplt.title(\"Loss Over Iterations wthout Momentum\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#test set evaluation/model loss\nloss = LR.loss(X_test, y_test)\nprint(f\"loss : {loss}\")\n#probabillity\ny_hat = 1/(1+torch.exp(-LR.score(X_test)))\n\n#make 0 or 1 \ny_pred = (y_hat &gt;= 0.5).float()\n\n#check for correct classification + mean for %correct\naccuracy = (y_pred == y_test).float().mean()\n\nprint(f\"accuracy : {accuracy}\")\n\nloss : 0.14749480783939362\naccuracy : 0.9666666388511658"
  },
  {
    "objectID": "posts/logisticRegression-post/LogisticModel.html#discussion",
    "href": "posts/logisticRegression-post/LogisticModel.html#discussion",
    "title": "Logistic Regression Blog Post",
    "section": "Discussion",
    "text": "Discussion\nIn this notebook, I utilized my own implementation of logistic regression to compare gradient descent with and without momentum, simulate overfitting to the data, and fit the model to an actual dataset. My model performs extremely well on this dataset, without being too computationally expensive. Logistic regression is a simple machine learning algorithm that performs well on binary classification tasks."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog :D"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lia Smith CSCI 0451 Blog",
    "section": "",
    "text": "Abstract\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPart 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizations and Table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic Regression Blog Post\n\n\n\n\n\nA blog post implementing logistic regression.\n\n\n\n\n\nApr 9, 2025\n\n\nLia Smith\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/kernal-methods-post/sparse-kernel-machines.html",
    "href": "posts/kernal-methods-post/sparse-kernel-machines.html",
    "title": "Abstract",
    "section": "",
    "text": "from logistic import KernelLogisticRegression\nIn this kernel logistic regression blog post, I expanded upon logistic regression by kernelizing the score and loss functions. Additionally, I explored the higher volatility that kernel function can bring to overfitting with gamma and lambda hyperparameters.\nimport torch\nfrom matplotlib import pyplot as plt\nplt.style.use('seaborn-v0_8-whitegrid')\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n   \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    # X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n   \n    X = X - X.mean(dim = 0, keepdim = True)\n    return X, y\n\n\ndef plot_classification_data(X, y, ax):\n    assert X.shape[1] == 2, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -1, vmax = 2, alpha = 0.8, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nX, y = classification_data(n_points = 100, noise = 0.4)\nplot_classification_data(X, y, ax)\ndef rbf_kernel(X_1, X_2, gamma=1.0):\n    return torch.exp(-gamma*torch.cdist(X_1, X_2)**2)\n#default kernel, encouraged to use others NOTE\nKR = KernelLogisticRegression(rbf_kernel, lam=0.1, gamma=1)\nKR.fit(X, y, m_epochs=50000, lr=0.0001)\n(1.0 * (KR.a &gt; 0.001)).mean()\n\ntensor(0.1900)\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:,0].min() - 0.2, X[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X[:,1].min() - 0.2, X[:,1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim = 1)\n\npreds = KR.score(X_)\npreds = 1.0*torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(X1, X2, preds, origin = \"lower\", cmap = \"BrBG\",\nvmin = 2*preds.min() - preds.max(), vmax = 2*preds.max() - preds.min()\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n# ax.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")"
  },
  {
    "objectID": "posts/kernal-methods-post/sparse-kernel-machines.html#changing-gamma",
    "href": "posts/kernal-methods-post/sparse-kernel-machines.html#changing-gamma",
    "title": "Large Lambda",
    "section": "Changing Gamma",
    "text": "Changing Gamma\n\nKR = KernelLogisticRegression(rbf_kernel, lam=.1, gamma=10)\nKR.fit(X, y, m_epochs=50000, lr=0.0001)\n(1.0 * (KR.a &gt; 0.001)).mean()\n\ntensor(0.)\n\n\n\nix = torch.abs(KR.a) &gt; 0.001\n\nx1 = torch.linspace(X[:,0].min() - 0.2, X[:,0].max() + 0.2, 101)\nx2 = torch.linspace(X[:,1].min() - 0.2, X[:,1].max() + 0.2, 101)\n\nX1, X2 = torch.meshgrid(x1, x2, indexing='ij')\n\nx1 = X1.ravel()\nx2 = X2.ravel()\n\nX_ = torch.stack((x1, x2), dim = 1)\n\npreds = KR.score(X_)\npreds = 1.0*torch.reshape(preds, X1.size())\n\nfig, ax = plt.subplots(1, 1)\nax.contourf(X1, X2, preds, origin = \"lower\", cmap = \"BrBG\",\nvmin = 2*preds.min() - preds.max(), vmax = 2*preds.max() - preds.min()\n)\nplot_classification_data(X, y, ax)\nplt.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")\n# ax.scatter(X[ix, 0],X[ix, 1], facecolors = \"none\", edgecolors = \"black\")"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/Overfitting-Overparameterization-blog-post/Overfitting.html",
    "href": "posts/Overfitting-Overparameterization-blog-post/Overfitting.html",
    "title": "Part 0",
    "section": "",
    "text": "from LinearRegressionOverfit import OverParameterizedLinearRegressionOptimizer, MyLinearRegression, RandomFeatures\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nw = (X^TX)^-1  X^T *y This matrix becomes uninvertable when there are more features than data points, because X^TX becomes a linearly dependent matrix that isn’t row reduceable. If (X^TX) isn’t invertable, then we cannot take the inverse of the matrix and cannot solve for w.\n\ndef add_bias(X):\n        \"\"\"\n        Adds a column of ones to X to account for the intercept term :D.\n\n        Arguments:\n            X, torch.Tensor: The feature matrix of size (n, p)\n\n        Returns:\n            X_with_bias, torch.Tensor: New matrix of size (n, p+1)\n        \"\"\"\n        n = X.size(0)\n        ones = torch.ones(n, 1) # make da onessss \n        return torch.cat((X, ones), dim=1)\n\n\n## Part A checks\nLR = MyLinearRegression()\nopt = OverParameterizedLinearRegressionOptimizer(LR)\n\nX = torch.tensor(np.linspace(-3, 3, 100).reshape(-1, 1), dtype = torch.float64)\ny = X**4 - 4*X + torch.normal(0, 5, size=X.shape)\n\nplt.scatter(X, y, color='darkgrey', label='Data')\nopt.fit(X, y)\n\n\n\n\n\n\n\n\n\n\n\n\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\nCell In[5], line 26\n     23 grid_inputs = torch.cat((grid_inputs, torch.ones((grid_inputs.shape[0], 1), dtype=torch.float64)), 1)\n     25 # Predict\n---&gt; 26 Z = LR.predict(grid_inputs).detach().numpy()\n     28 # Plot the decision boundary where prediction = 0.5\n     29 plt.contour(xx, yy, Z, levels=[0.5], colors='black', linewidths=2)\n\nFile c:\\Users\\liapu\\OneDrive\\Documents\\GitHub\\github.io\\posts\\Overfitting-Overparameterization-blog-post\\LinearRegressionOverfit.py:49, in MyLinearRegression.predict(self, X)\n     33 def predict(self, X):\n     34     \"\"\"\n     35     Compute the scores for each data point in the feature matrix X. \n     36     The formula for the ith entry of score is score[i] = &lt;self.w, x[i]&gt;. \n   (...)\n     47         score torch.Tensor: vector of scores. score.size() = (n,)\n     48     \"\"\"\n---&gt; 49     score = self.score(X)\n     50     return score\n\nFile c:\\Users\\liapu\\OneDrive\\Documents\\GitHub\\github.io\\posts\\Overfitting-Overparameterization-blog-post\\LinearRegressionOverfit.py:28, in LinearModel.score(self, X)\n     24     self.w = torch.rand((X.size()[1]), dtype=X.dtype)\n     27 # your computation here: compute the vector of scores s\n---&gt; 28 s = X @ self.w\n     29 return s\n\nRuntimeError: expected scalar type Double but found Float"
  },
  {
    "objectID": "posts/kernal-methods-post/sparse-kernel-machines.html#part-a-basic-experiments",
    "href": "posts/kernal-methods-post/sparse-kernel-machines.html#part-a-basic-experiments",
    "title": "Abstract",
    "section": "Part A: Basic Experiments",
    "text": "Part A: Basic Experiments\nThis section demonstrates basic functionality of the sparse kernel logistic regression implementation. I demontrate here how varying the regularization parameter λ and kernel width γ affects model sparsity and decision boundaries.\n\n## lambda\n\nlambdas = [0.01, 0.1, 1, 10, 100, 1000]\nnonzero_weights = []\n\nfor lam in lambdas:\n    KR = KernelLogisticRegression(rbf_kernel, lam=lam, gamma=1)\n    KR.fit(X, y, m_epochs=50000, lr=0.0001)\n    nonzero = (KR.a &gt; 0.001).sum()\n    nonzero_weights.append(nonzero)\n\nplt.plot(lambdas, nonzero_weights, marker='o')\nplt.xscale('log')\nplt.xlabel('Lambda (λ)')\nplt.ylabel('Number of nonzero weights')\nplt.title('Effect of λ on sparsity')\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nimport numpy as np\n\ndef plot_decision_boundary(model, X, y, h=0.02, title=None):\n    \"\"\"\n    Plots the decision boundary learned by a KernelLogisticRegression model.\n\n    Args:\n        model: Trained KernelLogisticRegression model.\n        X (torch.Tensor): Input data of shape (n, 2)\n        y (torch.Tensor): Labels of shape (n,)\n        h (float): Step size in the mesh.\n        title (str): Optional title for the plot.\n    \"\"\"\n    #torch to numpy\n    X_np = X.detach().numpy()\n    y_np = y.detach().numpy()\n\n    x_min, x_max = X_np[:, 0].min() - 1, X_np[:, 0].max() + 1\n    y_min, y_max = X_np[:, 1].min() - 1, X_np[:, 1].max() + 1\n\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    grid = np.c_[xx.ravel(), yy.ravel()]\n    grid_tensor = torch.from_numpy(grid).float()\n\n    # Get scores + sigmoid\n    with torch.no_grad():\n        scores = model.score(grid_tensor)\n        probs = torch.sigmoid(scores)\n\n    Z = probs.reshape(xx.shape)\n\n    # Plotlolol\n    plt.contourf(xx, yy, Z, levels=[0, 0.5, 1], alpha=0.3, colors=[\"#FFAAAA\", \"#AAAAFF\"])\n    plt.contour(xx, yy, Z, levels=[0.5], colors=\"k\", linewidths=1)\n\n    # Scatter original data\n    plt.scatter(X_np[y_np==0][:, 0], X_np[y_np==0][:, 1], c='red', label='Class 0', edgecolors='k')\n    plt.scatter(X_np[y_np==1][:, 0], X_np[y_np==1][:, 1], c='blue', label='Class 1', edgecolors='k')\n\n    plt.legend()\n    plt.title(title or \"Decision Boundary\")\n    plt.xlabel(\"x1\")\n    plt.ylabel(\"x2\")\n    plt.grid(True)\n    plt.show()\n\n\n## gamma\ngammas = [0.1, 1, 10]\nfor gamma in gammas:\n    KR = KernelLogisticRegression(rbf_kernel, lam=0.1, gamma=gamma)\n    KR.fit(X, y, m_epochs=50000, lr=0.0001)\n    plot_decision_boundary(KR, X, y, title=f'Decision Boundary with gamma={gamma}')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs the value of Gamma Increases, the fluidity of the decision boundry increases."
  },
  {
    "objectID": "posts/kernal-methods-post/sparse-kernel-machines.html#part-b-demonstrating-overfitting",
    "href": "posts/kernal-methods-post/sparse-kernel-machines.html#part-b-demonstrating-overfitting",
    "title": "Abstract",
    "section": "Part B: Demonstrating Overfitting",
    "text": "Part B: Demonstrating Overfitting\nI created two sets of data (training and testing) and show how the wrong choice of γ can lead to overfitting while visualizing both the decision boundary and performance using ROC curves.\n\nfrom sklearn.metrics import roc_curve, auc\ndef plot_roc_curves(model, X_train, y_train, X_test, y_test):\n    y_train_pred = model.score(X_train).detach().numpy()\n    y_test_pred = model.score(X_test).detach().numpy()\n\n    fpr_train, tpr_train, _ = roc_curve(y_train, y_train_pred)\n    fpr_test, tpr_test, _ = roc_curve(y_test, y_test_pred)\n\n    auc_train = auc(fpr_train, tpr_train)\n    auc_test = auc(fpr_test, tpr_test)\n\n    plt.figure(figsize=(8, 6))\n    plt.plot(fpr_train, tpr_train, label=f\"Train ROC (AUC = {auc_train:.2f})\", color='blue')\n    plt.plot(fpr_test, tpr_test, label=f\"Test ROC (AUC = {auc_test:.2f})\", color='red')\n    plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n    plt.title(\"ROC Curves: Overfit Model (high λ)\")\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n\nfrom sklearn.datasets import make_moons\n\nX, y = make_moons(n_samples=200, noise=0.4)\nX_test, y_test = make_moons(n_samples = 200, noise= 0.4)\n#np to tensor\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.float32)\n\n#model\nKR = KernelLogisticRegression(rbf_kernel, lam=0.5, gamma=100)\nKR.fit(X, y, m_epochs=50000, lr=0.0001)\nplot_decision_boundary(KR, X, y, title = \"Overfitting with Make Moons Data\")\n\nplot_roc_curves(KR, X, y, X_test, y_test)"
  }
]